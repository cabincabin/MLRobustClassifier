{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GCP_mlapis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "S5EgSNLvXywU"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Cloud Platform - Using Machine Learning APIs  ).\n",
        "\n",
        "This is an upgraded Python revision of [this notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/CPB100/lab4c/mlapis.ipynb).\n",
        "\n",
        "This notebook originally was being processed using DataLab on the Google Cloud Platform.  This particular incarnation of the notebook is for running on Google Colaboratory which I am trying out for the first time.\n",
        "\n",
        "### Security\n",
        "\n",
        "First things first - we need to authenticate against the Google Cloud APIs.\n",
        "\n",
        "#### Getting a Google API Credential.\n",
        "\n",
        "First, visit <a href=\"http://console.cloud.google.com/apis\">API console</a>, choose \"Credentials\" on the left-hand menu.  Choose \"Create Credentials\" and generate an API key for your application. You should probably restrict it by IP address to prevent abuse, but for now, just  leave that field blank and delete the API key after trying out this demo.\n",
        "\n",
        "Then, when you have your key, you will enter it in this first executable cell:"
      ]
    },
    {
      "metadata": {
        "id": "laePw6L_Rt8c",
        "colab_type": "code",
        "outputId": "0eeec280-3c39-41fd-dfe5-4d3726dc3359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "!pip install -q cloudstorage\n",
        "!pip install -q webapp2\n",
        "!pip install --upgrade numpy\n",
        "!pip install six==1.10.0\n",
        "!pip install -q datalab\n",
        "!pip install --upgrade gcs-client\n",
        "!pip install --upgrade google-cloud-storage\n",
        "!pip install --upgrade google-api-python-client\n",
        "!pip install opencv-python\n",
        "!pip install gcsfs\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!pip install -q cloudstorage\\n!pip install -q webapp2\\n!pip install --upgrade numpy\\n!pip install six==1.10.0\\n!pip install -q datalab\\n!pip install --upgrade gcs-client\\n!pip install --upgrade google-cloud-storage\\n!pip install --upgrade google-api-python-client\\n!pip install opencv-python\\n!pip install gcsfs\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "qpFSNLnt_1yL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Pz9dCCuaZgD7",
        "colab_type": "code",
        "outputId": "33ce5fdd-3a65-4756-c357-93a7b4576681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "APIKEY = getpass.getpass()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZnvgmLnVWWor",
        "colab_type": "code",
        "outputId": "12f89a4d-e77e-40c8-89bb-6fb352eafdd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import json\n",
        "import argparse\n",
        "import googleapiclient.discovery\n",
        "import pandas as pd\n",
        "import skimage.data\n",
        "from skimage import img_as_float\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import cv2\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "import io\n",
        "\n",
        "\n",
        "import sys\n",
        "import json\n",
        "import argparse\n",
        "import googleapiclient.discovery\n",
        "import pandas as pd\n",
        "import skimage.data\n",
        "from skimage import img_as_float\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import cv2\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "import io\n",
        "from google.cloud import storage\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras.callbacks import TensorBoard\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "jjQ4qVAe7h_3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Authenticate to GCS.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Create the service client.\n",
        "from googleapiclient.discovery import build\n",
        "gcs_service = build('storage', 'v1')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j6aK1R2Qkfdg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BUCKET='wpiopenimageskaggle'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hZnC-tvzrOVW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_service():\n",
        "    return googleapiclient.discovery.build('storage', 'v1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6xr2MR-i_A9A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def download_content(filename,BUCKET):\n",
        "    from google.cloud import storage\n",
        "    client = storage.Client('MLRobustClassifier')\n",
        "    bucket = client.get_bucket(BUCKET)\n",
        "    blob = storage.Blob(filename, bucket)\n",
        "    content = blob.download_as_string()\n",
        "    return(content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d24fYXEkkwMn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_image(filename):\n",
        "  from google.cloud import storage\n",
        "  client = storage.Client('MLRobustClassifier')\n",
        "  bucket = client.get_bucket(BUCKET)\n",
        "  blob = storage.Blob(filename, bucket)\n",
        "  content = blob.download_as_string()\n",
        "  img = Image.open(io.BytesIO(content))\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5xNjEFkG-Six",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def strip_filepath(infiles):\n",
        "    strip=[]\n",
        "    for path in infiles:\n",
        "        res=path.split(\"/\")\n",
        "        res=res[1]\n",
        "        res=res.split('.')\n",
        "        res=res[0]\n",
        "        strip.append(res)\n",
        "    files=pd.DataFrame()\n",
        "    files['ImageID']=strip\n",
        "    files['Url']=infiles\n",
        "    return(files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDNDhw3_V2UO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def list_bucket_pf(bucket, pf):\n",
        "    \"\"\"Returns a list of metadata of the objects within the given bucket.\"\"\"\n",
        "    service = create_service()\n",
        "\n",
        "    # Create a request to objects.list to retrieve a list of objects.\n",
        "    fields_to_return = 'nextPageToken,items(name,size,contentType,metadata(my-key))'\n",
        "    req = service.objects().list(bucket=bucket, fields=fields_to_return, prefix=pf)  # returns everything. UrbanSound is top dir in bucket\n",
        "\n",
        "    all_objects = []\n",
        "    # If you have too many items to list in one request, list_next() will\n",
        "    # automatically handle paging with the pageToken.\n",
        "    while req:\n",
        "        resp = req.execute()\n",
        "        all_objects.extend(resp.get('items', []))\n",
        "        req = service.objects().list_next(req, resp)\n",
        "    return all_objects\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2evA38OjphXv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def process_image(filename):\n",
        "  from google.cloud import storage\n",
        "  client = storage.Client('MLRobustClassifier')\n",
        "  bucket = client.get_bucket(BUCKET)\n",
        "  blob = storage.Blob(filename, bucket)\n",
        "  content = blob.download_as_string()\n",
        "  img = Image.open(io.BytesIO(content)).convert('L')\n",
        "  img=np.array(img)\n",
        "  return(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "54vYmj4W0jFL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def CreateDictLabels(Points):\n",
        "    dictOfLabels = {}\n",
        "    for point in Points:\n",
        "        labelkey = point['annotations'][0]['label'] #get the label\n",
        "        if labelkey not in dictOfLabels:\n",
        "            dictOfLabels.setdefault(labelkey, [])\n",
        "        dictOfLabels[labelkey].append(point['id'])\n",
        "    return dictOfLabels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PEsir_Qs0sGm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def CreateBatchOfImages(batchSize, labelDict):\n",
        "    global imageInputPath\n",
        "    ImageLabelDict = {}\n",
        "    SuccessNum = 0\n",
        "    for index in range(batchSize):\n",
        "        for labelkey in labelDict.keys():\n",
        "            if labelkey not in ImageLabelDict:\n",
        "                ImageLabelDict.setdefault(labelkey, [])\n",
        "\n",
        "            #force add one image, keep trying until one has been added, protects against corrupted images\n",
        "            while len(labelDict[labelkey]) != 0:\n",
        "                try:\n",
        "                    imageInputPath='Imagefiles256x256/'\n",
        "                    imageId = labelDict[labelkey].pop(0)\n",
        "                    uriInp = imageInputPath + imageId + \".jpg\"\n",
        "                    print(uriInp)\n",
        "                    '''\n",
        "                    with _open_file_read_binary(uriInp) as f:\n",
        "                        image_bytes = f.read()\n",
        "                        img = Image.open(io.BytesIO(image_bytes))\n",
        "                    '''\n",
        "\n",
        "                    #img= imageio.imread(uriInp)\n",
        "                        #img = Image.open(io.BytesIO(image_bytes))\n",
        "                    imgArr =  process_image(uriInp)\n",
        "                    print(imgArr)\n",
        "                except: #find image exception error for better style\n",
        "                    continue\n",
        "                else:\n",
        "                    ImageLabelDict[labelkey].append([imgArr, imageId])\n",
        "                    break\n",
        "        #make sure all have nonzero number of images left\n",
        " \n",
        "        SuccessNum += 1\n",
        "    return ImageLabelDict, labelDict, SuccessNum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "olE6_ydTzmCv",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e41788d7-ed9a-44bc-bc73-b00e2a73d942"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "file='PointAnnotationsSet256x256.txt'\n",
        "points = json.loads(uploaded[file].decode('utf-8'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-debf5a9a-0546-4661-aa95-540133c49f56\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-debf5a9a-0546-4661-aa95-540133c49f56\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving PointAnnotationsSet256x256.txt to PointAnnotationsSet256x256 (3).txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zFWwrZvn1ZJo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IdsFromLabels = CreateDictLabels(points)\n",
        "idsToRemoveFromEachBatch = IdsFromLabels.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1jRVwrtD3yB1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1317
        },
        "outputId": "d3c55f51-26dc-4ac6-ed43-cdb7e1f6de79"
      },
      "cell_type": "code",
      "source": [
        "ImageLabelDict, idsToRemoveFromEachBatch, SuccessNum = CreateBatchOfImages(10, idsToRemoveFromEachBatch)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imagefiles256x256/9eb39d618fd92994.jpg\n",
            "Imagefiles256x256/ad56d643354b9f53.jpg\n",
            "Imagefiles256x256/a7a1e58de7ce4154.jpg\n",
            "Imagefiles256x256/a2d0287ab2de8f2f.jpg\n",
            "Imagefiles256x256/4dc2c29d6202f84c.jpg\n",
            "Imagefiles256x256/66449e223b80a0a5.jpg\n",
            "Imagefiles256x256/7892ad7113275c6b.jpg\n",
            "Imagefiles256x256/5176cca60e245e3a.jpg\n",
            "Imagefiles256x256/5219cef5b7f9f7b4.jpg\n",
            "Imagefiles256x256/f81b23b5fafe03cc.jpg\n",
            "Imagefiles256x256/b458cec0a7092abe.jpg\n",
            "Imagefiles256x256/332635c359800b3f.jpg\n",
            "Imagefiles256x256/d24fb56ef73c5b02.jpg\n",
            "Imagefiles256x256/0e8ca0aca85b0c59.jpg\n",
            "Imagefiles256x256/70ad34e6faddbfe9.jpg\n",
            "Imagefiles256x256/67c4763f585892ce.jpg\n",
            "Imagefiles256x256/db3b44b6711e7e2c.jpg\n",
            "Imagefiles256x256/202d0c6ccef99ced.jpg\n",
            "Imagefiles256x256/ce9f38474ed595a4.jpg\n",
            "Imagefiles256x256/2aad92b4b57a7b3e.jpg\n",
            "Imagefiles256x256/bb703e867e1369bd.jpg\n",
            "Imagefiles256x256/e0cc9abb47f886b0.jpg\n",
            "Imagefiles256x256/807f839db4fcc4d1.jpg\n",
            "Imagefiles256x256/c85a9b5b8d81268b.jpg\n",
            "Imagefiles256x256/a38e9efbe565fc73.jpg\n",
            "Imagefiles256x256/6cbffcd1afd83b3b.jpg\n",
            "Imagefiles256x256/ed3a297b604eec23.jpg\n",
            "Imagefiles256x256/43fce31f75259026.jpg\n",
            "Imagefiles256x256/aa425b9150014859.jpg\n",
            "Imagefiles256x256/dabdbedf43ac5327.jpg\n",
            "Imagefiles256x256/6e101f1e0e7079ed.jpg\n",
            "Imagefiles256x256/e6b41161343bbb27.jpg\n",
            "Imagefiles256x256/a5174c0f1e2a7e1d.jpg\n",
            "Imagefiles256x256/98a5eccc0937af5a.jpg\n",
            "Imagefiles256x256/da8acf8f8b6d3aa1.jpg\n",
            "Imagefiles256x256/d2377b4ad9babb2d.jpg\n",
            "Imagefiles256x256/5854c8db07d3cb8e.jpg\n",
            "Imagefiles256x256/65d2cbc56f9f02f1.jpg\n",
            "Imagefiles256x256/172738f7e2d7fce4.jpg\n",
            "Imagefiles256x256/3606c17a0bf6aeb6.jpg\n",
            "Imagefiles256x256/d4a3e2bf967c42d3.jpg\n",
            "Imagefiles256x256/d5a72617d9ee8ce3.jpg\n",
            "Imagefiles256x256/18423e572162662e.jpg\n",
            "Imagefiles256x256/6ee3957a076b419e.jpg\n",
            "Imagefiles256x256/3dff09123231df13.jpg\n",
            "Imagefiles256x256/7166ef6c754349e4.jpg\n",
            "Imagefiles256x256/cf914518513b537a.jpg\n",
            "Imagefiles256x256/dd6b1ca782138eb8.jpg\n",
            "Imagefiles256x256/6e8ff04c3ea00140.jpg\n",
            "Imagefiles256x256/a173420cfdc0bc21.jpg\n",
            "Imagefiles256x256/09f8ef054832f9bf.jpg\n",
            "Imagefiles256x256/6469065ca6294ed3.jpg\n",
            "Imagefiles256x256/2f2eece29df92fde.jpg\n",
            "Imagefiles256x256/54c9377f3a57cc46.jpg\n",
            "Imagefiles256x256/8b79a42152b0a786.jpg\n",
            "Imagefiles256x256/e836ab9fe061ca30.jpg\n",
            "Imagefiles256x256/72d32f63e4d5692d.jpg\n",
            "Imagefiles256x256/ebe41c10973e9035.jpg\n",
            "Imagefiles256x256/26a88d4e0aff5018.jpg\n",
            "Imagefiles256x256/186ae9d9eeca76f7.jpg\n",
            "Imagefiles256x256/e0fe4c7189b4fe76.jpg\n",
            "Imagefiles256x256/065a347083833aaf.jpg\n",
            "Imagefiles256x256/08c4466b1a0a9c5f.jpg\n",
            "Imagefiles256x256/f8e2ab4ed72fe410.jpg\n",
            "Imagefiles256x256/3c516b93884e854a.jpg\n",
            "Imagefiles256x256/3deb7f9f13b3ae6e.jpg\n",
            "Imagefiles256x256/1d4614baaa513506.jpg\n",
            "Imagefiles256x256/2a85b3db6751c6d4.jpg\n",
            "Imagefiles256x256/9cb18db470d1cce2.jpg\n",
            "Imagefiles256x256/3a4cca6eab127955.jpg\n",
            "Imagefiles256x256/bdb9f0d335efca16.jpg\n",
            "Imagefiles256x256/38429590ed3e13ff.jpg\n",
            "Imagefiles256x256/f745985c27418328.jpg\n",
            "Imagefiles256x256/1b9e36b4e8fa41bf.jpg\n",
            "Imagefiles256x256/fa3c3b2578b31319.jpg\n",
            "Imagefiles256x256/7c14318fe49866fd.jpg\n",
            "Imagefiles256x256/85919b845107560d.jpg\n",
            "Imagefiles256x256/5a6ba94604bb2cd0.jpg\n",
            "Imagefiles256x256/10035c9c1985111d.jpg\n",
            "Imagefiles256x256/0f10ae6fe314c2dd.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xb2cQroL0QVr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "keys=list(ImageLabelDict.keys())\n",
        "data=[]\n",
        "labels=[]\n",
        "label=0\n",
        "for val in keys:\n",
        "  imgs=ImageLabelDict.get(val)\n",
        "  for img in imgs:\n",
        "        vec=img[0]\n",
        "        data.append(vec)\n",
        "        labels.append(label)\n",
        "  label+=1\n",
        "        \n",
        "    ########\n",
        "    ##\n",
        "    ##Split data intro training and testing wtih 0.75 train vs 0.25 test\n",
        "    ########\n",
        "        \n",
        "total=len(data)\n",
        "train_size=round(total*0.75)\n",
        "test_size=total-train_size\n",
        "import random\n",
        "random.seed(4)\n",
        "  \n",
        "train_ind=np.random.choice(len(labels),train_size,replace=False)\n",
        "test_ind=np.setdiff1d(list(range(0, total)),train_ind)\n",
        "\n",
        "\n",
        "labels_test=np.array(labels)\n",
        "data_test=np.array(data)\n",
        "    \n",
        "X_train=data_test[np.where(train_ind)]\n",
        "X_test=data_test[np.where(test_ind)]\n",
        "Y_train=labels_test[np.where(train_ind)]\n",
        "Y_test=labels_test[np.where(test_ind)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ju8SJjmY6U91",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "img_len=256\n",
        "img_width=256\n",
        "# We reshape the input data to have a depth of 1 (grey scale)\n",
        "if keras.backend.image_data_format() == 'channels_first':\n",
        "        X_train = X_train.reshape(X_train.shape[0], 1, img_len, img_width)\n",
        "        X_test = X_test.reshape(X_test.shape[0], 1, img_len, img_width)\n",
        "        input_shape = (1, img_len, img_width)\n",
        "else:\n",
        "        X_train = X_train.reshape(X_train.shape[0], img_len, img_width, 1)\n",
        "        X_test = X_test.reshape(X_test.shape[0], img_len, img_width, 1)\n",
        "        input_shape = (img_len, img_width, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R62poraW7H8G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    # Then we normalize it so that the values are between 0 and 1\n",
        "    X_train /= 255\n",
        "    X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mKBXkChO7JGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1171
        },
        "outputId": "f680dc18-b622-486b-8b90-534ca1a56295"
      },
      "cell_type": "code",
      "source": [
        "   # Defining the model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, 3, 3, activation='relu', input_shape=(img_len, img_width, 1)))\n",
        "    # 32 is the number of convolutional filters to use. Frist 3 is the number of rows in each convolution kernel and second 3 is the number of columns in each kernel.\n",
        "\n",
        "\n",
        "    model.add(Conv2D(32, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    # MaxPooling2D is a way to reduce the number of parameters in our model by sliding a 2x2 pooling filter across the previous layer and taking the max of the 4 values in the 2x2 filter.\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    # Dropout regularizes the model and prevents overfitting\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    # Final layer has the output size of 10 to correspond to the number of classes\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    # Fit model to training data\n",
        "    model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1)\n",
        "\n",
        "    # Evaluate the model on test data\n",
        "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "    print(\"test loss:\", score[0])\n",
        "    print(\"test accuracy:\",  score[1])\n",
        "    # score[0] gives you the test loss and score[1] gives you the accuracy\n",
        "\n",
        "    tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1, write_graph=True, write_grads=True, batch_size=32, write_images=True)\n",
        "\n",
        "    # We can use a call back to look into the internal state of the model during training\n",
        "    model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, Y_test), callbacks=[tbCallBack])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(256, 256,...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 254, 254, 32)      320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 252, 252, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 126, 126, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 126, 126, 32)      0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 508032)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65028224  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 65,039,082\n",
            "Trainable params: 65,039,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 20s 338ms/step - loss: 7.8634 - acc: 0.1186\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 16s 268ms/step - loss: 12.7899 - acc: 0.1356\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 16s 267ms/step - loss: 12.9775 - acc: 0.1356\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 16s 263ms/step - loss: 10.4583 - acc: 0.1695\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 16s 265ms/step - loss: 7.0262 - acc: 0.2203\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 16s 267ms/step - loss: 2.6094 - acc: 0.3898\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 16s 264ms/step - loss: 1.4933 - acc: 0.4576\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.9989 - acc: 0.7797\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 15s 257ms/step - loss: 0.6859 - acc: 0.8136\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.3913 - acc: 0.8814\n",
            "test loss: 0.2936042845249176\n",
            "test accuracy: 0.8999999761581421\n",
            "Train on 59 samples, validate on 20 samples\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 16s 279ms/step - loss: 0.3762 - acc: 0.9153 - val_loss: 0.2836 - val_acc: 0.9000\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 17s 283ms/step - loss: 0.2801 - acc: 0.8983 - val_loss: 0.2727 - val_acc: 0.9000\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 17s 281ms/step - loss: 0.2017 - acc: 0.9661 - val_loss: 0.2851 - val_acc: 0.9000\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 16s 278ms/step - loss: 0.2804 - acc: 0.9153 - val_loss: 0.2104 - val_acc: 0.9000\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 16s 275ms/step - loss: 0.2207 - acc: 0.9153 - val_loss: 0.1890 - val_acc: 0.9500\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 16s 279ms/step - loss: 0.2089 - acc: 0.9322 - val_loss: 0.2407 - val_acc: 0.9000\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 17s 280ms/step - loss: 0.1604 - acc: 0.9661 - val_loss: 0.3082 - val_acc: 0.9000\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 17s 287ms/step - loss: 0.1769 - acc: 0.9322 - val_loss: 0.3029 - val_acc: 0.9000\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 16s 279ms/step - loss: 0.1892 - acc: 0.9661 - val_loss: 0.2314 - val_acc: 0.9000\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 18s 312ms/step - loss: 0.1376 - acc: 0.9661 - val_loss: 0.1966 - val_acc: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2af6011d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "Ptkw9wWS9T42",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "outputId": "65264a95-0db9-4228-e6f3-473c46fcba84"
      },
      "cell_type": "code",
      "source": [
        "!pip install graphviz\n",
        "!pip install pydot\n",
        "!pip install pydotplus\n",
        "!pip install graphviz "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.3.0)\n",
            "Requirement already satisfied: pydotplus in /usr/local/lib/python3.6/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from pydotplus) (2.3.0)\n",
            "\u001b[31mInvalid requirement: '!apt-get'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/packaging/requirements.py\", line 93, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pyparsing.py\", line 1654, in parseString\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pyparsing.py\", line 1644, in parseString\n",
            "    loc, tokens = self._parse( instring, 0 )\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pyparsing.py\", line 1402, in _parseNoCache\n",
            "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pyparsing.py\", line 3417, in parseImpl\n",
            "    loc, exprtokens = e._parse( instring, loc, doActions )\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pyparsing.py\", line 1402, in _parseNoCache\n",
            "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pyparsing.py\", line 3739, in parseImpl\n",
            "    return self.expr._parse( instring, loc, doActions, callPreParse=False )\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pyparsing.py\", line 1402, in _parseNoCache\n",
            "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pyparsing.py\", line 3400, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse( instring, loc, doActions, callPreParse=False )\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pyparsing.py\", line 1406, in _parseNoCache\n",
            "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pyparsing.py\", line 2711, in parseImpl\n",
            "    raise ParseException(instring, loc, self.errmsg, self)\n",
            "pip._vendor.pyparsing.ParseException: Expected W:(abcd...) (at char 0), (line:1, col:1)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/req/constructors.py\", line 253, in install_req_from_line\n",
            "    req = Requirement(req)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/packaging/requirements.py\", line 96, in __init__\n",
            "    requirement_string[e.loc:e.loc + 8], e.msg\n",
            "pip._vendor.packaging.requirements.InvalidRequirement: Parse error at \"'!apt-get'\": Expected W:(abcd...)\n",
            "\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O13GjqVK9n1q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import os\n",
        "import pydot\n",
        "import graphviz\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vsWd2qhR9s8H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reparameterization trick\n",
        "# instead of sampling from Q(z|X), sample eps = N(0,I)\n",
        "# z = z_mean + sqrt(var)*eps\n",
        "def sampling(args):\n",
        "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
        "    # Arguments:\n",
        "        args (tensor): mean and log of variance of Q(z|X)\n",
        "    # Returns:\n",
        "        z (tensor): sampled latent vector\n",
        "    \"\"\"\n",
        "\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    # by default, random_normal has mean=0 and std=1.0\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "def plot_results(models,\n",
        "                 data,\n",
        "                 batch_size=128,\n",
        "                 model_name=\"vae_mnist\"):\n",
        "    \"\"\"Plots labels and MNIST digits as function of 2-dim latent vector\n",
        "    # Arguments:\n",
        "        models (tuple): encoder and decoder models\n",
        "        data (tuple): test data and label\n",
        "        batch_size (int): prediction batch size\n",
        "        model_name (string): which model is using this function\n",
        "    \"\"\"\n",
        "\n",
        "    encoder, decoder = models\n",
        "    x_test, y_test = data\n",
        "    os.makedirs(model_name, exist_ok=True)\n",
        "\n",
        "    filename = os.path.join(model_name, \"vae_mean.png\")\n",
        "    # display a 2D plot of the digit classes in the latent space\n",
        "    z_mean, _, _ = encoder.predict(x_test,\n",
        "                                   batch_size=batch_size)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.savefig(filename)\n",
        "    plt.show()\n",
        "\n",
        "    filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
        "    # display a 30x30 2D manifold of digits\n",
        "    n = 30\n",
        "    digit_size = 256\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "    # linearly spaced coordinates corresponding to the 2D plot\n",
        "    # of digit classes in the latent space\n",
        "    grid_x = np.linspace(-4, 4, n)\n",
        "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            z_sample = np.array([[xi, yi]])\n",
        "            x_decoded = decoder.predict(z_sample)\n",
        "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "            figure[i * digit_size: (i + 1) * digit_size,\n",
        "                   j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    start_range = digit_size // 2\n",
        "    end_range = n * digit_size + start_range + 1\n",
        "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "    sample_range_x = np.round(grid_x, 1)\n",
        "    sample_range_y = np.round(grid_y, 1)\n",
        "    plt.xticks(pixel_range, sample_range_x)\n",
        "    plt.yticks(pixel_range, sample_range_y)\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.imshow(figure, cmap='Greys_r')\n",
        "    plt.savefig(filename)\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4yinKUgQ-Td0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "deda0478-fd12-483f-e9bc-943418a36813"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.layers import Lambda, Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "\n",
        "import pydot\n",
        "import graphviz\n",
        "import pydotplus"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-26894058e7cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydotplus'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uR-eALbtBFvz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3b5f745f-ad40-42a9-f3eb-ada9a45f9918"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "RXvzZb0uAN_F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2048
        },
        "outputId": "94935a27-d82e-4dac-b4a4-b9da62f1a738"
      },
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y graphviz && pip install -q pydot\n",
        "import pydot"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package fontconfig.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 26397 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fontconfig_2.12.6-0ubuntu2_amd64.deb ...\n",
            "Unpacking fontconfig (2.12.6-0ubuntu2) ...\n",
            "Selecting previously unselected package libann0.\n",
            "Preparing to unpack .../01-libann0_1.1.2+doc-6_amd64.deb ...\n",
            "Unpacking libann0 (1.1.2+doc-6) ...\n",
            "Selecting previously unselected package libcdt5.\n",
            "Preparing to unpack .../02-libcdt5_2.40.1-2_amd64.deb ...\n",
            "Unpacking libcdt5 (2.40.1-2) ...\n",
            "Selecting previously unselected package libcgraph6.\n",
            "Preparing to unpack .../03-libcgraph6_2.40.1-2_amd64.deb ...\n",
            "Unpacking libcgraph6 (2.40.1-2) ...\n",
            "Selecting previously unselected package libjbig0:amd64.\n",
            "Preparing to unpack .../04-libjbig0_2.1-3.1build1_amd64.deb ...\n",
            "Unpacking libjbig0:amd64 (2.1-3.1build1) ...\n",
            "Selecting previously unselected package libtiff5:amd64.\n",
            "Preparing to unpack .../05-libtiff5_4.0.9-5_amd64.deb ...\n",
            "Unpacking libtiff5:amd64 (4.0.9-5) ...\n",
            "Selecting previously unselected package libwebp6:amd64.\n",
            "Preparing to unpack .../06-libwebp6_0.6.1-2_amd64.deb ...\n",
            "Unpacking libwebp6:amd64 (0.6.1-2) ...\n",
            "Selecting previously unselected package libxpm4:amd64.\n",
            "Preparing to unpack .../07-libxpm4_1%3a3.5.12-1_amd64.deb ...\n",
            "Unpacking libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Selecting previously unselected package libgd3:amd64.\n",
            "Preparing to unpack .../08-libgd3_2.2.5-4ubuntu0.2_amd64.deb ...\n",
            "Unpacking libgd3:amd64 (2.2.5-4ubuntu0.2) ...\n",
            "Selecting previously unselected package libgts-0.7-5:amd64.\n",
            "Preparing to unpack .../09-libgts-0.7-5_0.7.6+darcs121130-4_amd64.deb ...\n",
            "Unpacking libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
            "Selecting previously unselected package libpixman-1-0:amd64.\n",
            "Preparing to unpack .../10-libpixman-1-0_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-0:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libxcb-render0:amd64.\n",
            "Preparing to unpack .../11-libxcb-render0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-render0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libxcb-shm0:amd64.\n",
            "Preparing to unpack .../12-libxcb-shm0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-shm0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libcairo2:amd64.\n",
            "Preparing to unpack .../13-libcairo2_1.15.10-2_amd64.deb ...\n",
            "Unpacking libcairo2:amd64 (1.15.10-2) ...\n",
            "Selecting previously unselected package libltdl7:amd64.\n",
            "Preparing to unpack .../14-libltdl7_2.4.6-2_amd64.deb ...\n",
            "Unpacking libltdl7:amd64 (2.4.6-2) ...\n",
            "Selecting previously unselected package libthai-data.\n",
            "Preparing to unpack .../15-libthai-data_0.1.27-2_all.deb ...\n",
            "Unpacking libthai-data (0.1.27-2) ...\n",
            "Selecting previously unselected package libdatrie1:amd64.\n",
            "Preparing to unpack .../16-libdatrie1_0.2.10-7_amd64.deb ...\n",
            "Unpacking libdatrie1:amd64 (0.2.10-7) ...\n",
            "Selecting previously unselected package libthai0:amd64.\n",
            "Preparing to unpack .../17-libthai0_0.1.27-2_amd64.deb ...\n",
            "Unpacking libthai0:amd64 (0.1.27-2) ...\n",
            "Selecting previously unselected package libpango-1.0-0:amd64.\n",
            "Preparing to unpack .../18-libpango-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
            "Preparing to unpack .../19-libpangoft2-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
            "Preparing to unpack .../20-libpangocairo-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpathplan4.\n",
            "Preparing to unpack .../21-libpathplan4_2.40.1-2_amd64.deb ...\n",
            "Unpacking libpathplan4 (2.40.1-2) ...\n",
            "Selecting previously unselected package libgvc6.\n",
            "Preparing to unpack .../22-libgvc6_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgvc6 (2.40.1-2) ...\n",
            "Selecting previously unselected package libgvpr2.\n",
            "Preparing to unpack .../23-libgvpr2_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgvpr2 (2.40.1-2) ...\n",
            "Selecting previously unselected package liblab-gamut1.\n",
            "Preparing to unpack .../24-liblab-gamut1_2.40.1-2_amd64.deb ...\n",
            "Unpacking liblab-gamut1 (2.40.1-2) ...\n",
            "Selecting previously unselected package libxt6:amd64.\n",
            "Preparing to unpack .../25-libxt6_1%3a1.1.5-1_amd64.deb ...\n",
            "Unpacking libxt6:amd64 (1:1.1.5-1) ...\n",
            "Selecting previously unselected package libxmu6:amd64.\n",
            "Preparing to unpack .../26-libxmu6_2%3a1.1.2-2_amd64.deb ...\n",
            "Unpacking libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Selecting previously unselected package libxaw7:amd64.\n",
            "Preparing to unpack .../27-libxaw7_2%3a1.0.13-1_amd64.deb ...\n",
            "Unpacking libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Selecting previously unselected package graphviz.\n",
            "Preparing to unpack .../28-graphviz_2.40.1-2_amd64.deb ...\n",
            "Unpacking graphviz (2.40.1-2) ...\n",
            "Selecting previously unselected package libgts-bin.\n",
            "Preparing to unpack .../29-libgts-bin_0.7.6+darcs121130-4_amd64.deb ...\n",
            "Unpacking libgts-bin (0.7.6+darcs121130-4) ...\n",
            "Setting up libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
            "Setting up libpathplan4 (2.40.1-2) ...\n",
            "Setting up liblab-gamut1 (2.40.1-2) ...\n",
            "Setting up libxcb-render0:amd64 (1.13-1) ...\n",
            "Setting up libjbig0:amd64 (2.1-3.1build1) ...\n",
            "Setting up libdatrie1:amd64 (0.2.10-7) ...\n",
            "Setting up libtiff5:amd64 (4.0.9-5) ...\n",
            "Setting up libpixman-1-0:amd64 (0.34.0-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libltdl7:amd64 (2.4.6-2) ...\n",
            "Setting up libann0 (1.1.2+doc-6) ...\n",
            "Setting up libxcb-shm0:amd64 (1.13-1) ...\n",
            "Setting up libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Setting up libxt6:amd64 (1:1.1.5-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up libgts-bin (0.7.6+darcs121130-4) ...\n",
            "Setting up libthai-data (0.1.27-2) ...\n",
            "Setting up libcdt5 (2.40.1-2) ...\n",
            "Setting up fontconfig (2.12.6-0ubuntu2) ...\n",
            "Regenerating fonts cache... done.\n",
            "Setting up libcgraph6 (2.40.1-2) ...\n",
            "Setting up libwebp6:amd64 (0.6.1-2) ...\n",
            "Setting up libcairo2:amd64 (1.15.10-2) ...\n",
            "Setting up libgvpr2 (2.40.1-2) ...\n",
            "Setting up libgd3:amd64 (2.2.5-4ubuntu0.2) ...\n",
            "Setting up libthai0:amd64 (0.1.27-2) ...\n",
            "Setting up libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Setting up libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Setting up libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libgvc6 (2.40.1-2) ...\n",
            "Setting up graphviz (2.40.1-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c_nkuamc9zLY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "a5f7917b-4163-4d7c-c113-89aafc51ce6f"
      },
      "cell_type": "code",
      "source": [
        " # Then we normalize it so that the values are between 0 and 1\n",
        "    img_len=256\n",
        "    img_width=256\n",
        "    original_dim=img_len*img_width\n",
        "    x_train = X_train\n",
        "    x_test = X_test\n",
        "\n",
        "    \n",
        "    \n",
        "    # network parameters\n",
        "    input_shape = (original_dim, )\n",
        "    intermediate_dim = 512\n",
        "    batch_size = 128\n",
        "    latent_dim = 2\n",
        "    epochs = 40\n",
        "\n",
        "    # VAE model = encoder + decoder\n",
        "    # build encoder model\n",
        "    inputs = Input(shape=input_shape, name='encoder_input')\n",
        "    x = Dense(intermediate_dim, activation='relu')(inputs)\n",
        "    z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "    z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "    \n",
        "    # use reparameterization trick to push the sampling out as input\n",
        "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "    # instantiate encoder model\n",
        "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "    encoder.summary()\n",
        "    \n",
        "    plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n",
        "\n",
        "    # build decoder model\n",
        "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
        "    outputs = Dense(original_dim, activation='sigmoid')(x)\n",
        "    \n",
        "    # instantiate decoder model\n",
        "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "    decoder.summary()\n",
        "    plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)\n",
        "    \n",
        "    # instantiate VAE model\n",
        "    outputs = decoder(encoder(inputs)[2])\n",
        "    vae = Model(inputs, outputs, name='vae_mlp')\n",
        "\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    help_ = \"Load h5 model trained weights\"\n",
        "    parser.add_argument(\"-w\", \"--weights\", help=help_)\n",
        "    help_ = \"Use mse loss instead of binary cross entropy (default)\"\n",
        "    parser.add_argument(\"-m\",\n",
        "                        \"--mse\",\n",
        "                        help=help_, action='store_true')\n",
        "    args = parser.parse_args()\n",
        "    models = (encoder, decoder)\n",
        "    data = (x_test, y_test)\n",
        "    print(data)\n",
        "    \n",
        "\n",
        "# VAE loss = mse_loss or xent_loss + kl_loss\n",
        "    if args.mse:\n",
        "        reconstruction_loss = mse(inputs, outputs)\n",
        "    else:\n",
        "        reconstruction_loss = binary_crossentropy(inputs,\n",
        "                                                  outputs)\n",
        "\n",
        "    reconstruction_loss *= original_dim\n",
        "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "    kl_loss = K.sum(kl_loss, axis=-1)\n",
        "    kl_loss *= -0.5\n",
        "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "    vae.add_loss(vae_loss)\n",
        "    vae.compile(optimizer='adam')\n",
        "    vae.summary()\n",
        "    plot_model(vae,\n",
        "                   to_file='vae_mlp.png',\n",
        "                   show_shapes=True)\n",
        "        \n",
        "    if args.weights:\n",
        "        vae.load_weights(args.weights)\n",
        "    else:\n",
        "        # train the autoencoder\n",
        "        vae.fit(x_train,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        validation_data=(x_test, None))\n",
        "        vae.save_weights('vae_mlp_mnist.h5')\n",
        "                \n",
        "        plot_results(models,\n",
        "                             data,\n",
        "                             batch_size=batch_size,\n",
        "                             model_name=\"vae_mlp\")\n",
        "    \n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5ee8cdd3a60c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moriginal_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_len\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "BZ0MMdhNCOrd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***BELOW THIS POINT IS CODE TRIED THAT DOESN'T WORK KEPT FOR REFERENCE***"
      ]
    }
  ]
}